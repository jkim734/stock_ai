#!/usr/bin/env python3
"""
í†µí•© ë‰´ìŠ¤ & ë¦¬ì„œì¹˜ í¬ë¡¤ë§ ë° ë¶„ì„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
from datetime import datetime

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from news_analyzer import IntegratedNewsAnalyzer

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸš€ í†µí•© ë‰´ìŠ¤ & ë¦¬ì„œì¹˜ í¬ë¡¤ë§ ë° ë¶„ì„ ì‹œìŠ¤í…œ")
    print("=" * 80)
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}")
    print()

    # í†µí•© ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    analyzer = IntegratedNewsAnalyzer()

    print("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •:")
    print("   - ë‰´ìŠ¤ ì„¹ì…˜: ì •ì¹˜(101)")
    print("   - ë‰´ìŠ¤ ìˆ˜ì§‘ ê°œìˆ˜: 20ê°œ")
    print("   - ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ê°œìˆ˜: ì¹´í…Œê³ ë¦¬ë³„ 10ê°œì”©")
    print("   - AI ë¶„ì„: Gemini API í™œìš©")
    print()

    try:
        # í†µí•© í¬ë¡¤ë§ ë° ë¶„ì„ ì‹¤í–‰
        print("ğŸ¯ í†µí•© í¬ë¡¤ë§ ë° ë¶„ì„ ì‹œì‘...")
        result = analyzer.crawl_and_analyze_all(
            news_section_id="101",  # ì •ì¹˜ ì„¹ì…˜
            news_limit=20,          # ë‰´ìŠ¤ 20ê°œ
            reports_limit=10        # ì¹´í…Œê³ ë¦¬ë³„ ë¦¬í¬íŠ¸ 10ê°œì”©
        )

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        if result and 'metadata' in result:
            print("\n" + "=" * 80)
            print("ğŸ“Š í¬ë¡¤ë§ ë° ë¶„ì„ ê²°ê³¼ ìš”ì•½")
            print("=" * 80)

            metadata = result['metadata']
            summary = result.get('summary', {})

            print(f"ğŸ“° ë‰´ìŠ¤ í¬ë¡¤ë§:")
            print(f"   - ì´ ìˆ˜ì§‘ ë‰´ìŠ¤: {metadata.get('news_count', 0)}ê°œ")
            print(f"   - ë³¸ë¬¸ í¬ë¡¤ë§ ì„±ê³µ: {summary.get('successful_news_crawl', 0)}ê°œ")

            print(f"\nğŸ“ˆ ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ í¬ë¡¤ë§:")
            print(f"   - ì´ ìˆ˜ì§‘ ë¦¬í¬íŠ¸: {metadata.get('reports_count', 0)}ê°œ")
            print(f"   - ë³¸ë¬¸ í¬ë¡¤ë§ ì„±ê³µ: {summary.get('successful_reports_crawl', 0)}ê°œ")

            print(f"\nğŸ¤– AI ë¶„ì„ ê²°ê³¼:")
            news_analysis = result.get('news', {}).get('analysis', {})
            reports_analysis = result.get('research_reports', {}).get('analysis', {})

            if news_analysis and not news_analysis.get('error'):
                print(f"   - ë‰´ìŠ¤ ê°ì •: {news_analysis.get('overall_sentiment', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                print(f"   - ê°ì • ì ìˆ˜: {news_analysis.get('sentiment_score', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                print(f"   - í•µì‹¬ í…Œë§ˆ: {', '.join(news_analysis.get('key_themes', [])[:3])}")
                print(f"   - íˆ¬ì ì‹ í˜¸: {news_analysis.get('investment_signals', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            else:
                print(f"   - ë‰´ìŠ¤ ë¶„ì„: ì‹¤íŒ¨ ({news_analysis.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')})")

            if reports_analysis and not reports_analysis.get('error'):
                print(f"   - ì‹œì¥ ì „ë§: {reports_analysis.get('market_outlook', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                print(f"   - ì£¼ìš” ì¢…ëª©: {', '.join(reports_analysis.get('top_mentioned_stocks', [])[:3])}")
                print(f"   - í•µì‹¬ ì‚°ì—…: {', '.join(reports_analysis.get('key_industries', [])[:3])}")
            else:
                print(f"   - ë¦¬í¬íŠ¸ ë¶„ì„: ì‹¤íŒ¨ ({reports_analysis.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')})")

            # ì €ì¥ëœ íŒŒì¼ ì •ë³´
            if 'saved_file' in result:
                print(f"\nğŸ’¾ ê²°ê³¼ íŒŒì¼:")
                print(f"   - JSON íŒŒì¼: {result['saved_file']}")

                # íŒŒì¼ í¬ê¸° ê³„ì‚°
                try:
                    file_size = os.path.getsize(result['saved_file']) / 1024  # KB
                    print(f"   - íŒŒì¼ í¬ê¸°: {file_size:.1f} KB")
                except:
                    pass

            print(f"\nâ° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}")

            # ìƒì„¸ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
            print("\n" + "=" * 80)
            print("ğŸ“‹ ìƒì„¸ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
            print("=" * 80)

            # ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°
            news_data = result.get('news', {}).get('data', [])
            if news_data:
                print("ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤ (ì²˜ìŒ 3ê°œ):")
                for i, news in enumerate(news_data[:3], 1):
                    print(f"\n{i}. {news.get('title', 'ì œëª© ì—†ìŒ')}")
                    print(f"   ğŸ“… ë°œí–‰ì¼: {news.get('publish_date', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    print(f"   ğŸ“º ì–¸ë¡ ì‚¬: {news.get('media', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    print(f"   ğŸ“ ë³¸ë¬¸ ê¸¸ì´: {len(news.get('content', ''))}ì")

                    if news.get('content'):
                        preview = news['content'][:100] + "..." if len(news['content']) > 100 else news['content']
                        print(f"   ğŸ“– ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {preview}")

                if len(news_data) > 3:
                    print(f"\n   ... ë° {len(news_data) - 3}ê°œ ë”")

            # ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°
            reports_data = result.get('research_reports', {}).get('data', [])
            if reports_data:
                print(f"\nğŸ“ˆ ìˆ˜ì§‘ëœ ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ (ì²˜ìŒ 3ê°œ):")
                for i, report in enumerate(reports_data[:3], 1):
                    print(f"\n{i}. {report.get('title', 'ì œëª© ì—†ìŒ')}")
                    print(f"   ğŸ¢ ì¦ê¶Œì‚¬: {report.get('provider', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    print(f"   ğŸ“‚ ì¹´í…Œê³ ë¦¬: {report.get('category_name', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    print(f"   ğŸ“… ë°œí–‰ì¼: {report.get('publish_date', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    print(f"   ğŸ“ ìš”ì•½ ê¸¸ì´: {len(report.get('summary', ''))}ì")

                if len(reports_data) > 3:
                    print(f"\n   ... ë° {len(reports_data) - 3}ê°œ ë”")

            # ì„±ê³µë¥  í†µê³„
            print(f"\nğŸ“Š í¬ë¡¤ë§ ì„±ê³µë¥ :")
            if news_data:
                news_success_rate = (summary.get('successful_news_crawl', 0) / len(news_data)) * 100
                print(f"   - ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§: {news_success_rate:.1f}%")

            if reports_data:
                reports_success_rate = (summary.get('successful_reports_crawl', 0) / len(reports_data)) * 100
                print(f"   - ë¦¬í¬íŠ¸ ë³¸ë¬¸ í¬ë¡¤ë§: {reports_success_rate:.1f}%")

        else:
            print("âŒ í¬ë¡¤ë§ ë˜ëŠ” ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            print("ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ë‚˜ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print("\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        traceback.print_exc()

    print("\n" + "=" * 80)
    print("ğŸ í†µí•© ë‰´ìŠ¤ & ë¦¬ì„œì¹˜ ë¶„ì„ ì™„ë£Œ")
    print("=" * 80)

if __name__ == "__main__":
    main()
