<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/.gitignore">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/.gitignore" />
              <option name="originalContent" value="# Created by https://www.toptal.com/developers/gitignore/api/python,visualstudiocode,macos&#10;# Edit at https://www.toptal.com/developers/gitignore?templates=python,visualstudiocode,macos&#10;&#10;### macOS ###&#10;# General&#10;.DS_Store&#10;.AppleDouble&#10;.LSOverride&#10;&#10;# Icon must end with two \r&#10;Icon&#10;&#10;&#10;# Thumbnails&#10;._*&#10;&#10;# Files that might appear in the root of a volume&#10;.DocumentRevisions-V100&#10;.fseventsd&#10;.Spotlight-V100&#10;.TemporaryItems&#10;.Trashes&#10;.VolumeIcon.icns&#10;.com.apple.timemachine.donotpresent&#10;&#10;# Directories potentially created on remote AFP share&#10;.AppleDB&#10;.AppleDesktop&#10;Network Trash Folder&#10;Temporary Items&#10;.apdisk&#10;&#10;### macOS Patch ###&#10;# iCloud generated files&#10;*.icloud&#10;&#10;### Python ###&#10;# Byte-compiled / optimized / DLL files&#10;__pycache__/&#10;*.py[cod]&#10;*$py.class&#10;&#10;# C extensions&#10;*.so&#10;&#10;# Distribution / packaging&#10;.Python&#10;build/&#10;develop-eggs/&#10;dist/&#10;downloads/&#10;eggs/&#10;.eggs/&#10;lib/&#10;lib64/&#10;parts/&#10;sdist/&#10;var/&#10;wheels/&#10;share/python-wheels/&#10;*.egg-info/&#10;.installed.cfg&#10;*.egg&#10;MANIFEST&#10;&#10;# PyInstaller&#10;#  Usually these files are written by a python script from a template&#10;#  before PyInstaller builds the exe, so as to inject date/other infos into it.&#10;*.manifest&#10;*.spec&#10;&#10;# Installer logs&#10;pip-log.txt&#10;pip-delete-this-directory.txt&#10;&#10;# Unit test / coverage reports&#10;htmlcov/&#10;.tox/&#10;.nox/&#10;.coverage&#10;.coverage.*&#10;.cache&#10;nosetests.xml&#10;coverage.xml&#10;*.cover&#10;*.py,cover&#10;.hypothesis/&#10;.pytest_cache/&#10;cover/&#10;&#10;# Translations&#10;*.mo&#10;*.pot&#10;&#10;# Django stuff:&#10;*.log&#10;local_settings.py&#10;db.sqlite3&#10;db.sqlite3-journal&#10;&#10;# Flask stuff:&#10;instance/&#10;.webassets-cache&#10;&#10;# Scrapy stuff:&#10;.scrapy&#10;&#10;# Sphinx documentation&#10;docs/_build/&#10;&#10;# PyBuilder&#10;.pybuilder/&#10;target/&#10;&#10;# Jupyter Notebook&#10;.ipynb_checkpoints&#10;&#10;# IPython&#10;profile_default/&#10;ipython_config.py&#10;&#10;# pyenv&#10;#   For a library or package, you might want to ignore these files since the code is&#10;#   intended to run in multiple environments; otherwise, check them in:&#10;# .python-version&#10;&#10;# pipenv&#10;#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.&#10;#   However, in case of collaboration, if having platform-specific dependencies or dependencies&#10;#   having no cross-platform support, pipenv may install dependencies that don't work, or not&#10;#   install all needed dependencies.&#10;#Pipfile.lock&#10;&#10;# poetry&#10;#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.&#10;#   This is especially recommended for binary packages to ensure reproducibility, and is more&#10;#   commonly ignored for libraries.&#10;#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control&#10;#poetry.lock&#10;&#10;# pdm&#10;#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.&#10;#pdm.lock&#10;#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it&#10;#   in version control.&#10;#   https://pdm.fming.dev/#use-with-ide&#10;.pdm.toml&#10;&#10;# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm&#10;__pypackages__/&#10;&#10;# Celery stuff&#10;celerybeat-schedule&#10;celerybeat.pid&#10;&#10;# SageMath parsed files&#10;*.sage.py&#10;&#10;# Environments&#10;.env&#10;.venv&#10;env/&#10;venv/&#10;ENV/&#10;env.bak/&#10;venv.bak/&#10;&#10;# Spyder project settings&#10;.spyderproject&#10;.spyproject&#10;&#10;# Rope project settings&#10;.ropeproject&#10;&#10;# mkdocs documentation&#10;/site&#10;&#10;# mypy&#10;.mypy_cache/&#10;.dmypy.json&#10;dmypy.json&#10;&#10;# Pyre type checker&#10;.pyre/&#10;&#10;# pytype static type analyzer&#10;.pytype/&#10;&#10;# Cython debug symbols&#10;cython_debug/&#10;&#10;# PyCharm&#10;#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can&#10;#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore&#10;#  and can be added to the global gitignore or merged into this file.  For a more nuclear&#10;#  option (not recommended) you can uncomment the following to ignore the entire idea folder.&#10;#.idea/&#10;&#10;### Python Patch ###&#10;# Poetry local configuration file - https://python-poetry.org/docs/configuration/#local-configuration&#10;poetry.toml&#10;&#10;# ruff&#10;.ruff_cache/&#10;&#10;# LSP config files&#10;pyrightconfig.json&#10;&#10;### VisualStudioCode ###&#10;.vscode/*&#10;!.vscode/settings.json&#10;!.vscode/tasks.json&#10;!.vscode/launch.json&#10;!.vscode/extensions.json&#10;!.vscode/*.code-snippets&#10;&#10;# Local History for Visual Studio Code&#10;.history/&#10;&#10;# Built Visual Studio Code Extensions&#10;*.vsix&#10;&#10;### VisualStudioCode Patch ###&#10;# Ignore all local history of files&#10;.history&#10;.ionide&#10;&#10;# End of https://www.toptal.com/developers/gitignore/api/python,visualstudiocode,macos" />
              <option name="updatedContent" value="# Created by https://www.toptal.com/developers/gitignore/api/python,visualstudiocode,macos&#10;# Edit at https://www.toptal.com/developers/gitignore?templates=python,visualstudiocode,macos&#10;&#10;### macOS ###&#10;# General&#10;.DS_Store&#10;.AppleDouble&#10;.LSOverride&#10;&#10;# Icon must end with two \r&#10;Icon&#10;&#10;&#10;# Thumbnails&#10;._*&#10;&#10;# Files that might appear in the root of a volume&#10;.DocumentRevisions-V100&#10;.fseventsd&#10;.Spotlight-V100&#10;.TemporaryItems&#10;.Trashes&#10;.VolumeIcon.icns&#10;.com.apple.timemachine.donotpresent&#10;&#10;# Directories potentially created on remote AFP share&#10;.AppleDB&#10;.AppleDesktop&#10;Network Trash Folder&#10;Temporary Items&#10;.apdisk&#10;&#10;### macOS Patch ###&#10;# iCloud generated files&#10;*.icloud&#10;&#10;### Python ###&#10;# Byte-compiled / optimized / DLL files&#10;__pycache__/&#10;*.py[cod]&#10;*$py.class&#10;&#10;# C extensions&#10;*.so&#10;&#10;# Distribution / packaging&#10;.Python&#10;build/&#10;develop-eggs/&#10;dist/&#10;downloads/&#10;eggs/&#10;.eggs/&#10;lib/&#10;lib64/&#10;parts/&#10;sdist/&#10;var/&#10;wheels/&#10;share/python-wheels/&#10;*.egg-info/&#10;.installed.cfg&#10;*.egg&#10;MANIFEST&#10;&#10;# PyInstaller&#10;#  Usually these files are written by a python script from a template&#10;#  before PyInstaller builds the exe, so as to inject date/other infos into it.&#10;*.manifest&#10;*.spec&#10;&#10;# Installer logs&#10;pip-log.txt&#10;pip-delete-this-directory.txt&#10;&#10;# Unit test / coverage reports&#10;htmlcov/&#10;.tox/&#10;.nox/&#10;.coverage&#10;.coverage.*&#10;.cache&#10;nosetests.xml&#10;coverage.xml&#10;*.cover&#10;*.py,cover&#10;.hypothesis/&#10;.pytest_cache/&#10;cover/&#10;&#10;# Translations&#10;*.mo&#10;*.pot&#10;&#10;# Django stuff:&#10;*.log&#10;local_settings.py&#10;db.sqlite3&#10;db.sqlite3-journal&#10;&#10;# Flask stuff:&#10;instance/&#10;.webassets-cache&#10;&#10;# Scrapy stuff:&#10;.scrapy&#10;&#10;# Sphinx documentation&#10;docs/_build/&#10;&#10;# PyBuilder&#10;.pybuilder/&#10;target/&#10;&#10;# Jupyter Notebook&#10;.ipynb_checkpoints&#10;&#10;# IPython&#10;profile_default/&#10;ipython_config.py&#10;&#10;# pyenv&#10;#   For a library or package, you might want to ignore these files since the code is&#10;#   intended to run in multiple environments; otherwise, check them in:&#10;# .python-version&#10;&#10;# pipenv&#10;#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.&#10;#   However, in case of collaboration, if having platform-specific dependencies or dependencies&#10;#   having no cross-platform support, pipenv may install dependencies that don't work, or not&#10;#   install all needed dependencies.&#10;#Pipfile.lock&#10;&#10;# poetry&#10;#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.&#10;#   This is especially recommended for binary packages to ensure reproducibility, and is more&#10;#   commonly ignored for libraries.&#10;#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control&#10;#poetry.lock&#10;&#10;# pdm&#10;#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.&#10;#pdm.lock&#10;#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it&#10;#   in version control.&#10;#   https://pdm.fming.dev/#use-with-ide&#10;.pdm.toml&#10;&#10;# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm&#10;__pypackages__/&#10;&#10;# Celery stuff&#10;celerybeat-schedule&#10;celerybeat.pid&#10;&#10;# SageMath parsed files&#10;*.sage.py&#10;&#10;# Environments&#10;.env&#10;.venv&#10;env/&#10;venv/&#10;ENV/&#10;env.bak/&#10;venv.bak/&#10;&#10;# Spyder project settings&#10;.spyderproject&#10;.spyproject&#10;&#10;# Rope project settings&#10;.ropeproject&#10;&#10;# mkdocs documentation&#10;/site&#10;&#10;# mypy&#10;.mypy_cache/&#10;.dmypy.json&#10;dmypy.json&#10;&#10;# Pyre type checker&#10;.pyre/&#10;&#10;# pytype static type analyzer&#10;.pytype/&#10;&#10;# Cython debug symbols&#10;cython_debug/&#10;&#10;# PyCharm&#10;#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can&#10;#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore&#10;#  and can be added to the global gitignore or merged into this file.  For a more nuclear&#10;#  option (not recommended) you can uncomment the following to ignore the entire idea folder.&#10;#.idea/&#10;&#10;### Python Patch ###&#10;# Poetry local configuration file - https://python-poetry.org/docs/configuration/#local-configuration&#10;poetry.toml&#10;&#10;# ruff&#10;.ruff_cache/&#10;&#10;# LSP config files&#10;pyrightconfig.json&#10;&#10;### VisualStudioCode ###&#10;.vscode/*&#10;!.vscode/settings.json&#10;!.vscode/tasks.json&#10;!.vscode/launch.json&#10;!.vscode/extensions.json&#10;!.vscode/*.code-snippets&#10;&#10;# Local History for Visual Studio Code&#10;.history/&#10;&#10;# Built Visual Studio Code Extensions&#10;*.vsix&#10;&#10;### VisualStudioCode Patch ###&#10;# Ignore all local history of files&#10;.history&#10;.ionide&#10;&#10;# End of https://www.toptal.com/developers/gitignore/api/python,visualstudiocode,macos&#10;crawled_data_*.json&#10;analysis_result_*.json" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/debug_crawler.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/debug_crawler.py" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;네이버 증권 크롤링 디버깅용 스크립트&#10;실제 페이지 구조를 확인하여 문제점을 파악합니다.&#10;&quot;&quot;&quot;&#10;&#10;import requests&#10;from bs4 import BeautifulSoup&#10;import json&#10;&#10;def debug_research_page():&#10;    &quot;&quot;&quot;메인 리서치 페이지 구조 분석&quot;&quot;&quot;&#10;    url = &quot;https://finance.naver.com/research/&quot;&#10;    headers = {&#10;        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'&#10;    }&#10;    &#10;    try:&#10;        response = requests.get(url, headers=headers)&#10;        response.raise_for_status()&#10;        &#10;        soup = BeautifulSoup(response.content, 'html.parser')&#10;        &#10;        print(&quot;=== 네이버 증권 리서치 페이지 구조 분석 ===&quot;)&#10;        &#10;        # 모든 box_type_m 찾기&#10;        sections = soup.find_all('div', {'class': 'box_type_m'})&#10;        print(f&quot;box_type_m 섹션 개수: {len(sections)}&quot;)&#10;        &#10;        for i, section in enumerate(sections):&#10;            print(f&quot;\n--- 섹션 {i} ---&quot;)&#10;            &#10;            # 제목 찾기&#10;            title_elem = section.find('h4', {'class': 'h_sub2'})&#10;            if title_elem:&#10;                print(f&quot;제목: {title_elem.get_text(strip=True)}&quot;)&#10;            &#10;            # 테이블 찾기&#10;            table = section.find('table', {'class': 'type_1'})&#10;            if table:&#10;                print(&quot;테이블 발견!&quot;)&#10;                &#10;                # 테이블 헤더 확인&#10;                headers = table.find_all('th')&#10;                if headers:&#10;                    header_texts = [th.get_text(strip=True) for th in headers]&#10;                    print(f&quot;헤더: {header_texts}&quot;)&#10;                &#10;                # 첫 번째 데이터 행 확인&#10;                tbody = table.find('tbody')&#10;                if tbody:&#10;                    rows = tbody.find_all('tr')&#10;                else:&#10;                    rows = table.find_all('tr')[1:]  # 헤더 제외&#10;                &#10;                if rows:&#10;                    first_row = rows[0]&#10;                    cells = first_row.find_all('td')&#10;                    if cells:&#10;                        cell_texts = [td.get_text(strip=True) for td in cells]&#10;                        print(f&quot;첫 번째 행 데이터: {cell_texts}&quot;)&#10;                        &#10;                        # 링크 확인&#10;                        for j, cell in enumerate(cells):&#10;                            link = cell.find('a')&#10;                            if link:&#10;                                print(f&quot;  셀 {j}에 링크 발견: {link.get('href')}&quot;)&#10;            else:&#10;                print(&quot;테이블 없음&quot;)&#10;        &#10;        # 전체 페이지에서 &quot;종목분석&quot; 텍스트 찾기&#10;        page_text = soup.get_text()&#10;        if &quot;종목분석&quot; in page_text:&#10;            print(f&quot;\n'종목분석' 텍스트 발견됨&quot;)&#10;        else:&#10;            print(f&quot;\n'종목분석' 텍스트 없음&quot;)&#10;            &#10;    except Exception as e:&#10;        print(f&quot;오류 발생: {e}&quot;)&#10;&#10;def debug_news_detail():&#10;    &quot;&quot;&quot;뉴스 상세 페이지 구조 분석&quot;&quot;&quot;&#10;    # 샘플 뉴스 링크 (상대 경로를 절대 경로로 변환)&#10;    base_url = &quot;https://finance.naver.com&quot;&#10;    sample_link = &quot;/news/news_read.naver?article_id=0001218141&amp;office_id=215&amp;mode=mainnews&amp;type=&amp;date=2025-07-29&amp;page=1&quot;&#10;    full_url = base_url + sample_link&#10;    &#10;    headers = {&#10;        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'&#10;    }&#10;    &#10;    try:&#10;        response = requests.get(full_url, headers=headers)&#10;        response.raise_for_status()&#10;        &#10;        soup = BeautifulSoup(response.content, 'html.parser')&#10;        &#10;        print(&quot;\n=== 뉴스 상세 페이지 구조 분석 ===&quot;)&#10;        print(f&quot;URL: {full_url}&quot;)&#10;        &#10;        # 다양한 선택자로 본문 찾기 시도&#10;        content_selectors = [&#10;            '.newsct_article',&#10;            '.articleCont', &#10;            '.news_content',&#10;            '.article_view',&#10;            '.view_text',&#10;            '#news_read'&#10;        ]&#10;        &#10;        for selector in content_selectors:&#10;            element = soup.select_one(selector)&#10;            if element:&#10;                content = element.get_text(strip=True)&#10;                print(f&quot;선택자 '{selector}' 성공 - 내용 길이: {len(content)}&quot;)&#10;                if len(content) &gt; 0:&#10;                    print(f&quot;내용 미리보기: {content[:100]}...&quot;)&#10;                    break&#10;        else:&#10;            print(&quot;본문을 찾을 수 없음&quot;)&#10;        &#10;        # 날짜 찾기 시도&#10;        date_selectors = [&#10;            '.article_info .date',&#10;            '.newsct_date',&#10;            '.news_date',&#10;            '.date_time'&#10;        ]&#10;        &#10;        for selector in date_selectors:&#10;            element = soup.select_one(selector)&#10;            if element:&#10;                date_text = element.get_text(strip=True)&#10;                print(f&quot;선택자 '{selector}' 성공 - 날짜: {date_text}&quot;)&#10;                break&#10;        else:&#10;            print(&quot;날짜를 찾을 수 없음&quot;)&#10;            &#10;    except Exception as e:&#10;        print(f&quot;뉴스 상세 페이지 오류: {e}&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    debug_research_page()&#10;    debug_news_detail()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/diagnose_gemini.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/diagnose_gemini.py" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Gemini API 연결 진단 스크립트&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;from dotenv import load_dotenv&#10;import google.generativeai as genai&#10;&#10;def diagnose_gemini_connection():&#10;    &quot;&quot;&quot;Gemini API 연결 상태를 진단합니다.&quot;&quot;&quot;&#10;    &#10;    print(&quot; Gemini API 연결 진단 시작...&quot;)&#10;    &#10;    # 1. 환경 변수 확인&#10;    load_dotenv()&#10;    api_key = os.getenv(&quot;GOOGLE_AI_API_KEY&quot;)&#10;    &#10;    if not api_key:&#10;        print(&quot;❌ GOOGLE_AI_API_KEY 환경 변수가 설정되지 않았습니다.&quot;)&#10;        print(&quot; 해결 방법:&quot;)&#10;        print(&quot;   1. .env 파일을 생성하고 다음 내용을 추가하세요:&quot;)&#10;        print(&quot;      GOOGLE_AI_API_KEY=your_actual_api_key_here&quot;)&#10;        print(&quot;   2. Google AI Studio에서 API 키를 발급받으세요: https://aistudio.google.com/app/apikey&quot;)&#10;        return False&#10;    &#10;    print(f&quot;✅ API 키 확인됨 (길이: {len(api_key)} 문자)&quot;)&#10;    &#10;    # 2. API 키 형식 확인&#10;    if not api_key.startswith('AIza'):&#10;        print(&quot;⚠️  API 키 형식이 올바르지 않을 수 있습니다. (AIza로 시작해야 함)&quot;)&#10;    &#10;    # 3. API 연결 테스트&#10;    try:&#10;        print(&quot; Gemini API 연결 테스트 중...&quot;)&#10;        genai.configure(api_key=api_key)&#10;        &#10;        # 간단한 모델 호출 테스트&#10;        model = genai.GenerativeModel(&quot;gemini-2.0-flash-001&quot;)&#10;        &#10;        print(&quot; 간단한 테스트 요청 전송 중...&quot;)&#10;        response = model.generate_content(&#10;            &quot;안녕하세요를 영어로 번역해주세요.&quot;,&#10;            generation_config=genai.types.GenerationConfig(&#10;                temperature=0.1,&#10;                max_output_tokens=50&#10;            )&#10;        )&#10;        &#10;        print(&quot;✅ API 연결 성공!&quot;)&#10;        print(f&quot; 응답: {response.text}&quot;)&#10;        &#10;        # 토큰 사용량 확인&#10;        if hasattr(response, 'usage_metadata'):&#10;            print(f&quot; 토큰 사용량: {response.usage_metadata.total_token_count}&quot;)&#10;        &#10;        return True&#10;        &#10;    except Exception as e:&#10;        print(f&quot;❌ API 연결 실패: {e}&quot;)&#10;        &#10;        # 구체적인 오류 분석&#10;        error_str = str(e).lower()&#10;        if &quot;invalid api key&quot; in error_str or &quot;authentication&quot; in error_str:&#10;            print(&quot; API 키가 유효하지 않습니다.&quot;)&#10;            print(&quot;   - Google AI Studio에서 새로운 API 키를 발급받아보세요.&quot;)&#10;            print(&quot;   - API 키를 복사할 때 공백이나 특수문자가 포함되지 않았는지 확인하세요.&quot;)&#10;        elif &quot;quota&quot; in error_str or &quot;limit&quot; in error_str:&#10;            print(&quot; API 사용량 한도 초과입니다.&quot;)&#10;            print(&quot;   - 잠시 후 다시 시도하거나 유료 플랜을 고려해보세요.&quot;)&#10;        elif &quot;network&quot; in error_str or &quot;connection&quot; in error_str:&#10;            print(&quot; 네트워크 연결 문제입니다.&quot;)&#10;            print(&quot;   - 인터넷 연결을 확인하세요.&quot;)&#10;            print(&quot;   - VPN을 사용 중이라면 끄고 시도해보세요.&quot;)&#10;        else:&#10;            print(&quot;❓ 알 수 없는 오류입니다.&quot;)&#10;            print(f&quot;   상세 오류: {e}&quot;)&#10;        &#10;        return False&#10;&#10;def create_env_template():&#10;    &quot;&quot;&quot;환경 변수 템플릿 파일을 생성합니다.&quot;&quot;&quot;&#10;    env_content = &quot;&quot;&quot;# Google Gemini API 키&#10;# https://aistudio.google.com/app/apikey 에서 발급받으세요&#10;GOOGLE_AI_API_KEY=your_api_key_here&#10;&#10;# 사용 예시:&#10;# GOOGLE_AI_API_KEY=AIzaSyBxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&#10;&quot;&quot;&quot;&#10;    &#10;    with open('.env.template', 'w', encoding='utf-8') as f:&#10;        f.write(env_content)&#10;    &#10;    print(&quot; .env.template 파일이 생성되었습니다.&quot;)&#10;    print(&quot;   이 파일을 참고하여 .env 파일을 만들어주세요.&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    print(&quot;=&quot; * 50)&#10;    if not diagnose_gemini_connection():&#10;        print(&quot;\n 문제 해결 가이드:&quot;)&#10;        print(&quot;1. Google AI Studio 접속: https://aistudio.google.com/app/apikey&quot;)&#10;        print(&quot;2. 'Create API key' 클릭&quot;)&#10;        print(&quot;3. API 키 복사&quot;)&#10;        print(&quot;4. .env 파일에 GOOGLE_AI_API_KEY=복사한_키 추가&quot;)&#10;        print(&quot;5. 다시 실행&quot;)&#10;        &#10;        create_env_template()&#10;    print(&quot;=&quot; * 50)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/gemini.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/gemini.py" />
              <option name="originalContent" value="import time&#10;from typing import Optional&#10;from dotenv import load_dotenv&#10;import os&#10;import re&#10;import regex&#10;import json&#10;load_dotenv()&#10;&#10;from google import genai&#10;from google.genai import types&#10;&#10;model_name = &quot;gemini-2.0-flash-001&quot;&#10;&#10;# .env 파일에서 API 키 로드 (보안 강화)&#10;client = genai.Client(api_key=os.getenv(&quot;GOOGLE_AI_API_KEY&quot;))&#10;&#10;def ask_question_to_gemini_cache(prompt, max_retries=5, retry_delay=5):&#10;    &quot;&quot;&quot;&#10;    Gemini API를 사용하여 질문에 대한 답변을 얻습니다.&#10;    뉴스 분석에 최적화된 버전입니다.&#10;    &quot;&quot;&quot;&#10;    start_time = time.time()&#10;&#10;    for attempt in range(max_retries):&#10;        try:&#10;            # API 키 확인&#10;            api_key = os.getenv(&quot;GOOGLE_AI_API_KEY&quot;)&#10;            if not api_key:&#10;                raise Exception(&quot;GOOGLE_AI_API_KEY 환경 변수가 설정되지 않았습니다.&quot;)&#10;&#10;            api_start = time.time()&#10;&#10;            # Gemini API 호출&#10;            response = client.models.generate_content(&#10;                model=model_name,&#10;                contents=prompt,&#10;                config=types.GenerateContentConfig(&#10;                    temperature=0.3,&#10;                    max_output_tokens=2048&#10;                )&#10;            )&#10;&#10;            return response.text&#10;&#10;        except Exception as e:&#10;            error_msg = str(e).lower()&#10;            print(f&quot;API 오류 (시도 {attempt + 1}/{max_retries}): {e}&quot;)&#10;&#10;            if hasattr(e, 'code') and e.code == 503:&#10;                print(f&quot;⏳ API 사용량 한도 초과 (시도 {attempt + 1}/{max_retries}). {retry_delay}초 후 재시도...&quot;)&#10;                time.sleep(retry_delay)&#10;            elif &quot;invalid api key&quot; in error_msg or &quot;authentication&quot; in error_msg:&#10;                print(&quot;❌ API 키가 유효하지 않습니다. .env 파일을 확인하세요.&quot;)&#10;                break&#10;            elif &quot;quota&quot; in error_msg or &quot;limit&quot; in error_msg:&#10;                print(f&quot;⏳ API 사용량 한도 초과. {retry_delay}초 후 재시도...&quot;)&#10;                time.sleep(retry_delay)&#10;            else:&#10;                print(f&quot; Gemini API 오류 (시도 {attempt + 1}/{max_retries}): {e}&quot;)&#10;                if attempt == max_retries - 1:&#10;                    raise&#10;&#10;    print(f&quot;{max_retries}번 시도 후 실패. 총 소요시간: {time.time() - start_time:.2f}초&quot;)&#10;    return None&#10;&#10;def create_news_analysis_prompt(combined_text: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    뉴스 분석을 위한 통합 프롬프트 생성&#10;    &quot;&quot;&quot;&#10;    return f&quot;&quot;&quot;&#10;너는 국내 상장사와 주요 산업 분석에 특화된 금융 뉴스 분석 전문가야.&#10;&#10;{combined_text}&#10;&#10;뉴스 기사에 대해, 기계적 추출이 아닌 **생성적 요약**으로 다음 항목들을 JSON 형식으로 분석해주세요:&#10;&#10;1. overall_sentiment: 전체적인 시장 감정 (positive/negative/neutral)&#10;2. sentiment_score: 감정 점수 (-100 ~ +100, 숫자로만)&#10;3. key_themes: 주요 테마들 (배열)&#10;4. market_impact: 시장에 미칠 영향 예측 (2-3문장)&#10;5. summary: 전체 뉴스 요약 (3-4문장)&#10;6. investment_signals: 투자 시그널 (buy/sell/hold)&#10;&#10;### 출력 형식 (JSON)&#10;{{&#10;  &quot;overall_sentiment&quot;: &quot;positive/negative/neutral&quot;,&#10;  &quot;sentiment_score&quot;: 숫자,&#10;  &quot;key_themes&quot;: [&quot;테마1&quot;, &quot;테마2&quot;, &quot;테마3&quot;],&#10;  &quot;market_impact&quot;: &quot;시장 영향 분석&quot;,&#10;  &quot;summary&quot;: &quot;전체 뉴스 요약&quot;,&#10;  &quot;investment_signals&quot;: &quot;buy/sell/hold&quot;&#10;}}&#10;&#10;### 분석 가이드라인:&#10;• 답변 형식: 반드시 유효한 JSON 구조로 작성해주세요&#10;• 언어: 한국어로 자연스럽게 작성&#10;• 분석 스타일: 객관적이고 균형잡힌 관점 유지&#10;• 근거: 실제 데이터와 시장 동향에 기반한 분석&#10;• 투자 조언: 과도한 투기보다는 신중한 투자 관점 제시&#10;&#10;응답은 반드시 JSON 형식으로만 해주세요.&#10;&quot;&quot;&quot;&#10;&#10;def ask_news_analysis(prompt, max_retries=3):&#10;    &quot;&quot;&quot;&#10;    뉴스 분석 전용 Gemini API 호출 함수&#10;    JSON 응답을 기대하는 뉴스 분석에 최적화&#10;    &quot;&quot;&quot;&#10;    return ask_question_to_gemini_cache(prompt, max_retries=max_retries)&#10;&#10;def create_research_reports_analysis_prompt(combined_text: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    리서치 리포트 분석을 위한 통합 프롬프트 생성&#10;    &quot;&quot;&quot;&#10;    return f&quot;&quot;&quot;&#10;너는 국내 증권사 리서치 분석에 특화된 금융 전문가야.&#10;&#10;다음 네이버 증권 리서치 뉴스와 리포트들을 카테고리별로 분석해주세요:&#10;&#10;{combined_text}&#10;&#10;뉴스와 리포트에 대해, 종합적이고 심층적인 분석으로 다음 항목들을 JSON 형식으로 분석해주세요:&#10;&#10;1. category_summary: 카테고리별 요약 (각 카테고리당 2-3문장씩, 객체 형태)&#10;2. top_mentioned_stocks: 가장 많이 언급된 종목들 (배열, 최대 10개)&#10;3. key_industries: 주요 관심 산업/섹터들 (배열, 최대 8개)&#10;4. investment_themes: 주요 투자 테마들 (배열, 최대 8개)&#10;5. market_outlook: 전체 시장 전망 (bullish/bearish/neutral)&#10;6. risk_factors: 주요 리스크 요인들 (배열, 각 한 문장, 최대 5개)&#10;7. opportunities: 투자 기회들 (배열, 각 한 문장, 최대 5개)&#10;8. analyst_consensus: 애널리스트들의 전반적 합의 사항 (2-3문장)&#10;9. summary: 전체 리포트 종합 분석 (4-5문장)&#10;&#10;### 출력 형식 (JSON)&#10;{{&#10;  &quot;category_summary&quot;: {{&#10;    &quot;종목분석&quot;: &quot;종목분석 카테고리 요약 2-3문장&quot;,&#10;    &quot;산업분석&quot;: &quot;산업분석 카테고리 요약 2-3문장&quot;,&#10;    &quot;시황정보&quot;: &quot;시황정보 카테고리 요약 2-3문장&quot;,&#10;    &quot;투자정보&quot;: &quot;투자정보 카테고리 요약 2-3문장&quot;&#10;  }},&#10;  &quot;top_mentioned_stocks&quot;: [&quot;종목1&quot;, &quot;종목2&quot;, &quot;종목3&quot;],&#10;  &quot;key_industries&quot;: [&quot;산업1&quot;, &quot;산업2&quot;, &quot;산업3&quot;],&#10;  &quot;investment_themes&quot;: [&quot;테마1&quot;, &quot;테마2&quot;, &quot;테마3&quot;],&#10;  &quot;market_outlook&quot;: &quot;bullish/bearish/neutral&quot;,&#10;  &quot;risk_factors&quot;: [&quot;리스크 요인 1&quot;, &quot;리스크 요인 2&quot;],&#10;  &quot;opportunities&quot;: [&quot;투자 기회 1&quot;, &quot;투자 기회 2&quot;],&#10;  &quot;analyst_consensus&quot;: &quot;애널리스트 합의 사항 2-3문장&quot;,&#10;  &quot;summary&quot;: &quot;전체 종합 분석 4-5문장&quot;&#10;}}&#10;&#10;### 분석 가이드라인:&#10;• 답변 형식: 반드시 유효한 JSON 구조로 작성해주세요&#10;• 언어: 한국어로 자연스럽게 작성&#10;• 분석 스타일: 객관적이고 전문적인 관점 유지&#10;• 근거: 실제 리포트 내용과 시장 동향에 기반한 분석&#10;• 투자 조언: 신중하고 균형잡힌 투자 관점 제시&#10;• 완성도: 모든 9개 항목을 빠짐없이 포함해야 함&#10;&#10;응답은 반드시 JSON 형식으로만 해주세요.&#10;&quot;&quot;&quot;&#10;&#10;def json_match(input_string):&#10;    &quot;&quot;&quot;&#10;    Use regex to extract JSON from a string.&#10;    &quot;&quot;&quot;&#10;    if not input_string:&#10;        return None&#10;&#10;    print(&quot;응답 텍스트에서 JSON 추출 시도...&quot;)&#10;&#10;    # 1. 백틱으로 감싸진 JSON 찾기 (개선된 regex 사용)&#10;    pattern_backticks = r'```json\s*(\{.*?\})\s*```'&#10;    m = re.search(pattern_backticks, input_string, re.DOTALL)&#10;    if m:&#10;        json_str = m.group(1)&#10;        try:&#10;            result = json.loads(json_str)&#10;            print(&quot;백틱 JSON 추출 성공&quot;)&#10;            return result&#10;        except json.JSONDecodeError as e:&#10;            print(f&quot;백틱 JSON 파싱 실패: {e}&quot;)&#10;            # 손상된 JSON 복구 시도&#10;            fixed_json = _try_fix_json(json_str)&#10;            if fixed_json:&#10;                return fixed_json&#10;&#10;    # 2. regex 라이브러리가 있다면 고급 패턴 사용&#10;    try:&#10;        pattern_simple = r'(\{(?:[^{}]|(?R))*\})'&#10;        m = regex.search(pattern_simple, input_string)&#10;        if m:&#10;            json_str = m.group(1)&#10;            try:&#10;                result = json.loads(json_str)&#10;                print(&quot;고급 regex JSON 추출 성공&quot;)&#10;                return result&#10;            except json.JSONDecodeError as e:&#10;                print(f&quot;고급 regex JSON 파싱 실패: {e}&quot;)&#10;                # 손상된 JSON 복구 시도&#10;                fixed_json = _try_fix_json(json_str)&#10;                if fixed_json:&#10;                    return fixed_json&#10;    except NameError:&#10;        # regex 라이브러리가 없는 경우 기본 패턴 사용&#10;        pass&#10;&#10;    # 3. 기본 re 모듈로 간단한 패턴 시도&#10;    try:&#10;        # 여러 JSON 객체를 찾아서 가장 완전한 것 선택&#10;        json_candidates = []&#10;&#10;        # 모든 { } 찾기&#10;        brace_count = 0&#10;        start_pos = -1&#10;&#10;        for i, char in enumerate(input_string):&#10;            if char == '{':&#10;                if brace_count == 0:&#10;                    start_pos = i&#10;                brace_count += 1&#10;            elif char == '}':&#10;                brace_count -= 1&#10;                if brace_count == 0 and start_pos != -1:&#10;                    json_candidate = input_string[start_pos:i+1]&#10;                    json_candidates.append(json_candidate)&#10;&#10;        # 가장 긴 JSON 후보를 먼저 시도&#10;        json_candidates.sort(key=len, reverse=True)&#10;&#10;        for json_str in json_candidates:&#10;            try:&#10;                result = json.loads(json_str)&#10;                print(&quot;기본 JSON 추출 성공&quot;)&#10;                return result&#10;            except json.JSONDecodeError:&#10;                # 손상된 JSON 복구 시도&#10;                fixed_json = _try_fix_json(json_str)&#10;                if fixed_json:&#10;                    return fixed_json&#10;                continue&#10;&#10;    except Exception as e:&#10;        print(f&quot;기본 JSON 파싱 중 오류: {e}&quot;)&#10;&#10;    print(&quot;JSON 추출 실패&quot;)&#10;    return None&#10;&#10;def _try_fix_json(json_str: str) -&gt; Optional[dict]:&#10;    &quot;&quot;&quot;&#10;    손상된 JSON을 복구하려고 시도&#10;    &quot;&quot;&quot;&#10;    print(&quot;손상된 JSON 복구 시도...&quot;)&#10;&#10;    try:&#10;        # 1. 흔한 문제들 수정&#10;        fixed_str = json_str&#10;&#10;        # 잘못된 키 이름 패턴 수정 (예: &quot;텍스트key&quot;: -&gt; &quot;key&quot;:)&#10;        import re&#10;        fixed_str = re.sub(r'&quot;[^&quot;]*[가-힣][^&quot;]*([a-zA-Z_][a-zA-Z0-9_]*)&quot;:', r'&quot;\1&quot;:', fixed_str)&#10;&#10;        # 중간에 끊어진 문자열 + 키 패턴 수정&#10;        fixed_str = re.sub(r'&quot;[^&quot;]*&quot;([a-zA-Z_][a-zA-Z0-9_]*)&quot;:', r'&quot;, &quot;\1&quot;:', fixed_str)&#10;&#10;        # 잘 구분된 쉼표 패턴 수정&#10;        fixed_str = re.sub(r',\s*}', '}', fixed_str)&#10;        fixed_str = re.sub(r',\s*]', ']', fixed_str)&#10;&#10;        # 2. JSON 파싱 재시도&#10;        result = json.loads(fixed_str)&#10;        print(&quot;JSON 복구 성공!&quot;)&#10;        return result&#10;&#10;    except json.JSONDecodeError as e:&#10;        print(f&quot;JSON 복구 실패: {e}&quot;)&#10;&#10;        # 3. 부분 복구 시도 - 유효한 필드만 추출&#10;        try:&#10;            partial_data = {}&#10;&#10;            # 간단한 키-값 쌍 추출&#10;            simple_patterns = [&#10;                (r'&quot;([^&quot;]+)&quot;:\s*&quot;([^&quot;]*)&quot;', str),  # 문자열 값&#10;                (r'&quot;([^&quot;]+)&quot;:\s*(\d+(?:\.\d+)?)', float),  # 숫자 값&#10;                (r'&quot;([^&quot;]+)&quot;:\s*(true|false)', bool),  # 불린 값&#10;            ]&#10;&#10;            for pattern, value_type in simple_patterns:&#10;                matches = re.findall(pattern, json_str)&#10;                for key, value in matches:&#10;                    try:&#10;                        if value_type == bool:&#10;                            partial_data[key] = value.lower() == 'true'&#10;                        elif value_type == float:&#10;                            partial_data[key] = float(value)&#10;                        else:&#10;                            partial_data[key] = value&#10;                    except:&#10;                        continue&#10;&#10;            if partial_data:&#10;                print(f&quot;부분 JSON 복구 성공: {len(partial_data)}개 필드&quot;)&#10;                return partial_data&#10;&#10;        except Exception as e:&#10;            print(f&quot;부분 복구도 실패: {e}&quot;)&#10;&#10;    return None" />
              <option name="updatedContent" value="import time&#10;from typing import Optional&#10;from dotenv import load_dotenv&#10;import os&#10;import re&#10;import regex&#10;import json&#10;load_dotenv()&#10;&#10;from google import genai&#10;from google.genai import types&#10;&#10;model_name = &quot;gemini-2.0-flash-001&quot;&#10;&#10;# .env 파일에서 API 키 로드 (보안 강화)&#10;client = genai.Client(api_key=os.getenv(&quot;GOOGLE_AI_API_KEY&quot;))&#10;&#10;def ask_question_to_gemini_cache(prompt, max_retries=5, retry_delay=5):&#10;    &quot;&quot;&quot;&#10;    Gemini API를 사용하여 질문에 대한 답변을 얻습니다.&#10;    뉴스 분석에 최적화된 버전입니다.&#10;    &quot;&quot;&quot;&#10;    start_time = time.time()&#10;&#10;    for attempt in range(max_retries):&#10;        try:&#10;            # API 키 확인&#10;            api_key = os.getenv(&quot;GOOGLE_AI_API_KEY&quot;)&#10;            if not api_key:&#10;                raise Exception(&quot;GOOGLE_AI_API_KEY 환경 변수가 설정되지 않았습니다.&quot;)&#10;&#10;            api_start = time.time()&#10;&#10;            # Gemini API 호출&#10;            response = client.models.generate_content(&#10;                model=model_name,&#10;                contents=prompt,&#10;                config=types.GenerateContentConfig(&#10;                    temperature=0.3,&#10;                    max_output_tokens=2048&#10;                )&#10;            )&#10;&#10;            return response.text&#10;&#10;        except Exception as e:&#10;            error_msg = str(e).lower()&#10;            print(f&quot;API 오류 (시도 {attempt + 1}/{max_retries}): {e}&quot;)&#10;&#10;            if hasattr(e, 'code') and e.code == 503:&#10;                print(f&quot;⏳ API 사용량 한도 초과 (시도 {attempt + 1}/{max_retries}). {retry_delay}초 후 재시도...&quot;)&#10;                time.sleep(retry_delay)&#10;            elif &quot;invalid api key&quot; in error_msg or &quot;authentication&quot; in error_msg:&#10;                print(&quot;❌ API 키가 유효하지 않습니다. .env 파일을 확인하세요.&quot;)&#10;                break&#10;            elif &quot;quota&quot; in error_msg or &quot;limit&quot; in error_msg:&#10;                print(f&quot;⏳ API 사용량 한도 초과. {retry_delay}초 후 재시도...&quot;)&#10;                time.sleep(retry_delay)&#10;            else:&#10;                print(f&quot; Gemini API 오류 (시도 {attempt + 1}/{max_retries}): {e}&quot;)&#10;                if attempt == max_retries - 1:&#10;                    raise&#10;&#10;    print(f&quot;{max_retries}번 시도 후 실패. 총 소요시간: {time.time() - start_time:.2f}초&quot;)&#10;    return None&#10;&#10;def create_news_analysis_prompt(combined_text: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    뉴스 분석을 위한 통합 프롬프트 생성&#10;    &quot;&quot;&quot;&#10;    return f&quot;&quot;&quot;&#10;너는 국내 상장사와 주요 산업 분석에 특화된 금융 뉴스 분석 전문가야.&#10;&#10;{combined_text}&#10;&#10;뉴스 기사에 대해, 기계적 추출이 아닌 **생성적 요약**으로 다음 항목들을 JSON 형식으로 분석해주세요:&#10;&#10;1. overall_sentiment: 전체적인 시장 감정 (positive/negative/neutral)&#10;2. sentiment_score: 감정 점수 (-100 ~ +100, 숫자로만)&#10;3. key_themes: 주요 테마들 (배열)&#10;4. market_impact: 시장에 미칠 영향 예측 (2-3문장)&#10;5. summary: 전체 뉴스 요약 (3-4문장)&#10;6. investment_signals: 투자 시그널 (buy/sell/hold)&#10;&#10;### 출력 형식 (JSON)&#10;{{&#10;  &quot;overall_sentiment&quot;: &quot;positive/negative/neutral&quot;,&#10;  &quot;sentiment_score&quot;: 숫자,&#10;  &quot;key_themes&quot;: [&quot;테마1&quot;, &quot;테마2&quot;, &quot;테마3&quot;],&#10;  &quot;market_impact&quot;: &quot;시장 영향 분석&quot;,&#10;  &quot;summary&quot;: &quot;전체 뉴스 요약&quot;,&#10;  &quot;investment_signals&quot;: &quot;buy/sell/hold&quot;&#10;}}&#10;&#10;### 분석 가이드라인:&#10;• 답변 형식: 반드시 유효한 JSON 구조로 작성해주세요&#10;• 언어: 한국어로 자연스럽게 작성&#10;• 분석 스타일: 객관적이고 균형잡힌 관점 유지&#10;• 근거: 실제 데이터와 시장 동향에 기반한 분석&#10;• 투자 조언: 과도한 투기보다는 신중한 투자 관점 제시&#10;&#10;응답은 반드시 JSON 형식으로만 해주세요.&#10;&quot;&quot;&quot;&#10;&#10;def ask_news_analysis(prompt, max_retries=3):&#10;    &quot;&quot;&quot;&#10;    뉴스 분석 전용 Gemini API 호출 함수&#10;    JSON 응답을 기대하는 뉴스 분석에 최적화&#10;    &quot;&quot;&quot;&#10;    return ask_question_to_gemini_cache(prompt, max_retries=max_retries)&#10;&#10;def create_research_reports_analysis_prompt(combined_text: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    리서치 리포트 분석을 위한 통합 프롬프트 생성&#10;    &quot;&quot;&quot;&#10;    return f&quot;&quot;&quot;&#10;너는 국내 증권사 리서치 분석에 특화된 금융 전문가야.&#10;&#10;다음 네이버 증권 리서치 뉴스와 리포트들을 카테고리별로 분석해주세요:&#10;&#10;{combined_text}&#10;&#10;뉴스와 리포트에 대해, 종합적이고 심층적인 분석으로 다음 항목들을 JSON 형식으로 분석해주세요:&#10;&#10;1. category_summary: 카테고리별 요약 (각 카테고리당 2-3문장씩, 객체 형태)&#10;2. top_mentioned_stocks: 가장 많이 언급된 종목들 (배열, 최대 10개)&#10;3. key_industries: 주요 관심 산업/섹터들 (배열, 최대 8개)&#10;4. investment_themes: 주요 투자 테마들 (배열, 최대 8개)&#10;5. market_outlook: 전체 시장 전망 (bullish/bearish/neutral)&#10;6. risk_factors: 주요 리스크 요인들 (배열, 각 한 문장, 최대 5개)&#10;7. opportunities: 투자 기회들 (배열, 각 한 문장, 최대 5개)&#10;8. analyst_consensus: 애널리스트들의 전반적 합의 사항 (2-3문장)&#10;9. summary: 전체 리포트 종합 분석 (4-5문장)&#10;&#10;### 출력 형식 (JSON)&#10;{{&#10;  &quot;category_summary&quot;: {{&#10;    &quot;종목분석&quot;: &quot;종목분석 카테고리 요약 2-3문장&quot;,&#10;    &quot;산업분석&quot;: &quot;산업분석 카테고리 요약 2-3문장&quot;,&#10;    &quot;시황정보&quot;: &quot;시황정보 카테고리 요약 2-3문장&quot;,&#10;    &quot;투자정보&quot;: &quot;투자정보 카테고리 요약 2-3문장&quot;&#10;  }},&#10;  &quot;top_mentioned_stocks&quot;: [&quot;종목1&quot;, &quot;종목2&quot;, &quot;종목3&quot;],&#10;  &quot;key_industries&quot;: [&quot;산업1&quot;, &quot;산업2&quot;, &quot;산업3&quot;],&#10;  &quot;investment_themes&quot;: [&quot;테마1&quot;, &quot;테마2&quot;, &quot;테마3&quot;],&#10;  &quot;market_outlook&quot;: &quot;bullish/bearish/neutral&quot;,&#10;  &quot;risk_factors&quot;: [&quot;리스크 요인 1&quot;, &quot;리스크 요인 2&quot;],&#10;  &quot;opportunities&quot;: [&quot;투자 기회 1&quot;, &quot;투자 기회 2&quot;],&#10;  &quot;analyst_consensus&quot;: &quot;애널리스트 합의 사항 2-3문장&quot;,&#10;  &quot;summary&quot;: &quot;전체 종합 분석 4-5문장&quot;&#10;}}&#10;&#10;### 분석 가이드라인:&#10;• 답변 형식: 반드시 유효한 JSON 구조로 작성해주세요&#10;• 언어: 한국어로 자연스럽게 작성&#10;• 분석 스타일: 객관적이고 전문적인 관점 유지&#10;• 근거: 실제 리포트 내용과 시장 동향에 기반한 분석&#10;• 투자 조언: 신중하고 균형잡힌 투자 관점 제시&#10;• 완성도: 모든 9개 항목을 빠짐없이 포함해야 함&#10;&#10;응답은 반드시 JSON 형식으로만 해주세요.&#10;&quot;&quot;&quot;&#10;&#10;def create_individual_news_analysis_prompt(news_item: dict) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    개별 뉴스 분석을 위한 프롬프트 생성&#10;    &quot;&quot;&quot;&#10;    title = news_item.get('title', '')&#10;    content = news_item.get('content', '')&#10;    &#10;    # 내용이 없으면 제목만 사용&#10;    text_to_analyze = content if content.strip() else title&#10;    &#10;    return f&quot;&quot;&quot;&#10;너는 국내 상장사와 주요 산업 분석에 특화된 금융 뉴스 분석 전문가야.&#10;&#10;다음 뉴스 기사를 분석해주세요:&#10;&#10;제목: {title}&#10;내용: {text_to_analyze[:500]}&#10;&#10;뉴스 기사에 대해, 기계적 추출이 아닌 **생성적 요약**으로 다음 항목들을 JSON 형식으로 분석해주세요:&#10;&#10;1. summary: 주요 이슈 한 문장 요약&#10;2. entities: 관련 기업명과/또는 업종명 명시&#10;3. impact: 업계·시장 파급 영��� 또는 의미 부각&#10;4. type: 기업 또는 산업 (정확히 이 두 단어 중 하나만)&#10;5. reason: 이 기사 분류의 근거 (기업/산업)&#10;&#10;### 분류 지침:&#10;- 특정 기업(예: 삼성전자, 현대차 등)에 대한 기사면 &quot;type&quot;: &quot;기업&quot;으로,&#10;- 정부 정책, 산업 정책, 경제 지표(금리, 환율 등), 법/제도, 또는 특정 산업 전체에 대한 기사면 &quot;type&quot;: &quot;산업&quot;으로 분류.&#10;- 분류 사유는 기사 내용 근거를 1문장으로 명확히 설명할 것.&#10;&#10;### 출력 형식 (JSON)&#10;{{&#10;  &quot;summary&quot;: &quot;&lt;주요 이슈 한 문장 요약&gt;&quot;,&#10;  &quot;entities&quot;: &quot;&lt;관련 기업명과/또는 업종명 명시&gt;&quot;,&#10;  &quot;impact&quot;: &quot;&lt;업계·시장 파급 영향 또는 의미 부각&gt;&quot;,&#10;  &quot;type&quot;: &quot;기업 또는 산업&quot;,&#10;  &quot;reason&quot;: &quot;&lt;이 기사 분류의 근거 (기업/산업)&gt;&quot;&#10;}}&#10;&#10;### 분석 가이드라인:&#10;• 답변 형식: 반드시 유효한 JSON 구조로 작성해주세요&#10;• 언어: 한국어로 자연스럽게 작��&#10;• 분석 스타일: 객관적이고 균형잡힌 관점 유지&#10;• 근거: 실제 데이터와 시장 동향에 기반한 분석&#10;• 투자 조언: 과도한 투기보다는 신중한 투자 관점 제시&#10;&#10;응답은 반드시 JSON 형식으로만 해주세요.&#10;&quot;&quot;&quot;&#10;&#10;def json_match(input_string):&#10;    &quot;&quot;&quot;&#10;    Use regex to extract JSON from a string.&#10;    &quot;&quot;&quot;&#10;    if not input_string:&#10;        return None&#10;&#10;    print(&quot;응답 텍스트에서 JSON 추출 시도...&quot;)&#10;&#10;    # 1. 백틱으로 감싸진 JSON 찾기 (개선된 regex 사용)&#10;    pattern_backticks = r'```json\s*(\{.*?\})\s*```'&#10;    m = re.search(pattern_backticks, input_string, re.DOTALL)&#10;    if m:&#10;        json_str = m.group(1)&#10;        try:&#10;            result = json.loads(json_str)&#10;            print(&quot;백틱 JSON 추출 성공&quot;)&#10;            return result&#10;        except json.JSONDecodeError as e:&#10;            print(f&quot;백틱 JSON 파싱 실패: {e}&quot;)&#10;            # 손상된 JSON 복구 시도&#10;            fixed_json = _try_fix_json(json_str)&#10;            if fixed_json:&#10;                return fixed_json&#10;&#10;    # 2. regex 라이브러리가 있다면 고급 패턴 사용&#10;    try:&#10;        pattern_simple = r'(\{(?:[^{}]|(?R))*\})'&#10;        m = regex.search(pattern_simple, input_string)&#10;        if m:&#10;            json_str = m.group(1)&#10;            try:&#10;                result = json.loads(json_str)&#10;                print(&quot;고급 regex JSON 추출 성공&quot;)&#10;                return result&#10;            except json.JSONDecodeError as e:&#10;                print(f&quot;고급 regex JSON 파싱 실패: {e}&quot;)&#10;                # 손상된 JSON 복구 시도&#10;                fixed_json = _try_fix_json(json_str)&#10;                if fixed_json:&#10;                    return fixed_json&#10;    except NameError:&#10;        # regex 라이브러리가 없는 경우 기본 패턴 사용&#10;        pass&#10;&#10;    # 3. 기본 re 모듈로 간단한 패턴 시도&#10;    try:&#10;        # 여러 JSON 객체를 찾아서 가장 완전한 것 선택&#10;        json_candidates = []&#10;&#10;        # 모든 { } 찾기&#10;        brace_count = 0&#10;        start_pos = -1&#10;&#10;        for i, char in enumerate(input_string):&#10;            if char == '{':&#10;                if brace_count == 0:&#10;                    start_pos = i&#10;                brace_count += 1&#10;            elif char == '}':&#10;                brace_count -= 1&#10;                if brace_count == 0 and start_pos != -1:&#10;                    json_candidate = input_string[start_pos:i+1]&#10;                    json_candidates.append(json_candidate)&#10;&#10;        # 가장 긴 JSON 후보를 먼저 시도&#10;        json_candidates.sort(key=len, reverse=True)&#10;&#10;        for json_str in json_candidates:&#10;            try:&#10;                result = json.loads(json_str)&#10;                print(&quot;기본 JSON 추출 성공&quot;)&#10;                return result&#10;            except json.JSONDecodeError:&#10;                # 손상된 JSON 복구 시도&#10;                fixed_json = _try_fix_json(json_str)&#10;                if fixed_json:&#10;                    return fixed_json&#10;                continue&#10;&#10;    except Exception as e:&#10;        print(f&quot;기본 JSON 파싱 중 오류: {e}&quot;)&#10;&#10;    print(&quot;JSON 추출 실패&quot;)&#10;    return None&#10;&#10;def _try_fix_json(json_str: str) -&gt; Optional[dict]:&#10;    &quot;&quot;&quot;&#10;    손상된 JSON을 복구하려고 시도&#10;    &quot;&quot;&quot;&#10;    print(&quot;손상된 JSON 복구 시도...&quot;)&#10;&#10;    try:&#10;        # 1. 흔한 문제들 수정&#10;        fixed_str = json_str&#10;&#10;        # 잘못된 키 이름 패턴 수정 (예: &quot;텍스트key&quot;: -&gt; &quot;key&quot;:)&#10;        import re&#10;        fixed_str = re.sub(r'&quot;[^&quot;]*[가-힣][^&quot;]*([a-zA-Z_][a-zA-Z0-9_]*)&quot;:', r'&quot;\1&quot;:', fixed_str)&#10;&#10;        # 중간에 끊어진 문자열 + 키 패턴 수정&#10;        fixed_str = re.sub(r'&quot;[^&quot;]*&quot;([a-zA-Z_][a-zA-Z0-9_]*)&quot;:', r'&quot;, &quot;\1&quot;:', fixed_str)&#10;&#10;        # 잘 구분된 쉼표 패턴 수정&#10;        fixed_str = re.sub(r',\s*}', '}', fixed_str)&#10;        fixed_str = re.sub(r',\s*]', ']', fixed_str)&#10;&#10;        # 2. JSON 파싱 재시도&#10;        result = json.loads(fixed_str)&#10;        print(&quot;JSON 복구 성공!&quot;)&#10;        return result&#10;&#10;    except json.JSONDecodeError as e:&#10;        print(f&quot;JSON 복구 실패: {e}&quot;)&#10;&#10;        # 3. 부분 복구 시도 - 유효한 필드만 추출&#10;        try:&#10;            partial_data = {}&#10;&#10;            # 간단한 키-값 쌍 추출&#10;            simple_patterns = [&#10;                (r'&quot;([^&quot;]+)&quot;:\s*&quot;([^&quot;]*)&quot;', str),  # 문자열 값&#10;                (r'&quot;([^&quot;]+)&quot;:\s*(\d+(?:\.\d+)?)', float),  # 숫자 값&#10;                (r'&quot;([^&quot;]+)&quot;:\s*(true|false)', bool),  # 불린 값&#10;            ]&#10;&#10;            for pattern, value_type in simple_patterns:&#10;                matches = re.findall(pattern, json_str)&#10;                for key, value in matches:&#10;                    try:&#10;                        if value_type == bool:&#10;                            partial_data[key] = value.lower() == 'true'&#10;                        elif value_type == float:&#10;                            partial_data[key] = float(value)&#10;                        else:&#10;                            partial_data[key] = value&#10;                    except:&#10;                        continue&#10;&#10;            if partial_data:&#10;                print(f&quot;부분 JSON 복구 성공: {len(partial_data)}개 필드&quot;)&#10;                return partial_data&#10;&#10;        except Exception as e:&#10;            print(f&quot;부분 복구도 실패: {e}&quot;)&#10;&#10;    return None" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/main.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/main.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;네이버 증권 뉴스 크롤링 및 AI 분석 시스템 메인 실행 파일&#10;&quot;&quot;&quot;&#10;&#10;import json&#10;import logging&#10;from datetime import datetime&#10;from news_crawler import NaverStockNewsCrawler&#10;from news_analyzer import NewsAnalyzer&#10;&#10;# 로깅 설정 (간단한 진행 상황 표시)&#10;logging.basicConfig(&#10;    level=logging.INFO,  # WARNING에서 INFO로 복구&#10;    format='%(message)s',  # 간단한 메시지만 출력&#10;    handlers=[&#10;        logging.FileHandler(f'stock_analysis_{datetime.now().strftime(&quot;%Y%m%d&quot;)}.log'),&#10;        logging.StreamHandler()  # 콘솔 출력 복구&#10;    ]&#10;)&#10;&#10;logger = logging.getLogger(__name__)&#10;&#10;class StockNewsAnalysisSystem:&#10;    &quot;&quot;&quot;주식 뉴스 분석 시스템 메인 클래스&quot;&quot;&quot;&#10;&#10;    def __init__(self):&#10;        self.crawler = NaverStockNewsCrawler()&#10;        self.analyzer = NewsAnalyzer()&#10;&#10;    def run_daily_analysis(self, news_limit: int = 10, reports_limit: int = 10) -&gt; dict:&#10;        &quot;&quot;&quot;&#10;        일일 뉴스 분석 실행 (카테고리별 상세 분석 포함)&#10;&#10;        Args:&#10;            news_limit: 크롤링할 뉴스 개수&#10;            reports_limit: 각 카테고리별로 크롤링할 리포트 개수&#10;&#10;        Returns:&#10;            Dict: 전체 분석 결과&#10;        &quot;&quot;&quot;&#10;        logger.info(&quot;--- 일일 주식 뉴스 분석 시작 ---&quot;)&#10;&#10;        try:&#10;            # 1. 뉴스 및 리포트 크롤링&#10;            logger.info(&quot;1단계: 뉴스 및 리포트 크롤링 시작&quot;)&#10;            crawled_data = self.crawler.get_today_summary()&#10;&#10;            if crawled_data['total_count'] == 0:&#10;                logger.warning(&quot;크롤링된 데이터가 없습니다.&quot;)&#10;                return {&quot;error&quot;: &quot;크롤링된 데이터가 없습니다.&quot;}&#10;&#10;            # 크롤링 현황 출력&#10;            logger.info(f&quot;뉴스 크롤링: {len(crawled_data['main_news'])}개&quot;)&#10;            logger.info(f&quot;리포트 크롤링: {len(crawled_data['research_reports'])}개&quot;)&#10;&#10;            # 카테고리별 통계 출력&#10;            category_counts = {}&#10;            for report in crawled_data['research_reports']:&#10;                category = report.get('category_name', 'Unknown')&#10;                category_counts[category] = category_counts.get(category, 0) + 1&#10;&#10;            if category_counts:&#10;                for category, count in category_counts.items():&#10;                    logger.info(f&quot;  {category}: {count}개&quot;)&#10;&#10;            # 2. AI 분석 수행 (카테고리별 상세 분석 포함)&#10;            logger.info(&quot;Gemini API 분석 시작&quot;)&#10;            analysis_result = self.analyzer.analyze_comprehensive_with_categories(crawled_data)&#10;&#10;            # 3. 결과 저장&#10;            self._save_results(crawled_data, analysis_result)&#10;&#10;            logger.info(&quot;분석 완료&quot;)&#10;&#10;            return {&#10;                'crawled_data': crawled_data,&#10;                'analysis_result': analysis_result,&#10;                'status': 'success'&#10;            }&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;분석 시스템 실행 중 오류: {e}&quot;)&#10;            return {&quot;error&quot;: f&quot;시스템 실행 중 오류: {str(e)}&quot;}&#10;&#10;    def _save_results(self, crawled_data: dict, analysis_result: dict):&#10;        &quot;&quot;&quot;분석 결과를 파일로 저장&quot;&quot;&quot;&#10;        timestamp = datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;)&#10;&#10;        # 크롤링 데이터 저장&#10;        with open(f'crawled_data_{timestamp}.json', 'w', encoding='utf-8') as f:&#10;            json.dump(crawled_data, f, ensure_ascii=False, indent=2)&#10;&#10;        # 분석 결과 저장&#10;        with open(f'analysis_result_{timestamp}.json', 'w', encoding='utf-8') as f:&#10;            json.dump(analysis_result, f, ensure_ascii=False, indent=2)&#10;&#10;        logger.info(f&quot;결과 파일 저장 완료: crawled_data_{timestamp}.json, analysis_result_{timestamp}.json&quot;)&#10;&#10;    def print_summary(self, result: dict):&#10;        &quot;&quot;&quot;분석 결과 요약 출력 (간소화된 버전)&quot;&quot;&quot;&#10;        if 'error' in result:&#10;            print(f&quot;❌ 오류: {result['error']}&quot;)&#10;            return&#10;&#10;        analysis = result['analysis_result']&#10;&#10;        print(&quot;\n&quot; + &quot;-&quot;*50)&#10;        print(&quot;&lt;오늘의 주식 시장 분석 결과&gt;&quot;)&#10;        print(&quot;-&quot;*50)&#10;&#10;        # 뉴스 분석 요약&#10;        if 'news_analysis' in analysis:&#10;            news = analysis['news_analysis']&#10;            print(f&quot;\n 뉴스 분석 ({news.get('news_count', 0)}개)&quot;)&#10;            print(f&quot;   감정: {news.get('overall_sentiment', 'N/A')}&quot;)&#10;            print(f&quot;   점수: {news.get('sentiment_score', 'N/A')}/100&quot;)&#10;            if 'summary' in news:&#10;                print(f&quot;   요약: {news['summary']}&quot;)&#10;&#10;        # 리포트 분석 요약 (카테고리별)&#10;        if 'reports_analysis' in analysis:&#10;            reports = analysis['reports_analysis']&#10;            print(f&quot;\n 리포트 분석 ({reports.get('reports_count', 0)}개)&quot;)&#10;            print(f&quot;   시장 전망: {reports.get('market_outlook', 'N/A')}&quot;)&#10;&#10;            if 'top_mentioned_stocks' in reports:&#10;                stocks = reports['top_mentioned_stocks'][:5]&#10;                if stocks:&#10;                    print(f&quot;   주목 종목: {', '.join(stocks)}&quot;)&#10;&#10;        # 일일 종합 분석&#10;        if 'daily_report' in analysis:&#10;            daily = analysis['daily_report']&#10;            if 'error' not in daily:&#10;                print(f&quot;\n⭐ 종합 평가&quot;)&#10;                print(f&quot;   시장 감정 점수: {daily.get('market_sentiment_score', 'N/A')}/10&quot;)&#10;                print(f&quot;   신뢰도: {daily.get('confidence_level', 'N/A')}/10&quot;)&#10;&#10;    def print_detailed_category_analysis(self, result: dict):&#10;        &quot;&quot;&quot;카테고리별 상세 분석 결과 출력 (간소화된 버전)&quot;&quot;&quot;&#10;        if 'error' in result or 'category_insights' not in result['analysis_result']:&#10;            return&#10;&#10;        analysis = result['analysis_result']&#10;        insights = analysis['category_insights']&#10;&#10;        if 'category_statistics' in insights:&#10;            print(f&quot;\n&quot; + &quot;-&quot;*50)&#10;            print(&quot;&lt;카테고리별 상세 분석&gt;&quot;)&#10;&#10;            stats = insights['category_statistics']&#10;            for category, data in stats.items():&#10;                print(f&quot;\n {category}&quot;)&#10;                print(f&quot;   리포트 수: {data.get('count', 0)}개&quot;)&#10;                if data.get('mentioned_stocks'):&#10;                    print(f&quot;   언급된 종목: {', '.join(data['mentioned_stocks'][:3])}&quot;)&#10;&#10;def main():&#10;    &quot;&quot;&quot;메인 실행 함수&quot;&quot;&quot;&#10;    print(&quot; 네이버 증권 AI 분석 시스템&quot;)&#10;&#10;    # 시스템 초기화&#10;    system = StockNewsAnalysisSystem()&#10;&#10;    # 분석 실행&#10;    result = system.run_daily_analysis(news_limit=20, reports_limit=5)&#10;&#10;    # 기본 요약 결과 출력&#10;    system.print_summary(result)&#10;&#10;    # 카테고리별 상세 분석 출력 (리포트가 있을 때만)&#10;    system.print_detailed_category_analysis(result)&#10;&#10;    print(f&quot;\n{'-'*50}&quot;)&#10;    print(&quot;&lt;분석 완료&gt;&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;네이버 증권 뉴스 크롤링 및 AI 분석 시스템 메인 실행 파일&#10;&quot;&quot;&quot;&#10;&#10;import json&#10;import logging&#10;from datetime import datetime&#10;from news_crawler import NaverStockNewsCrawler&#10;from news_analyzer import NewsAnalyzer&#10;&#10;# 로깅 설정 (간단한 진행 상황 표시)&#10;logging.basicConfig(&#10;    level=logging.INFO,  # WARNING에서 INFO로 복구&#10;    format='%(message)s',  # 간단한 메시지만 출력&#10;    handlers=[&#10;        logging.StreamHandler()  # 콘솔 출력만&#10;    ]&#10;)&#10;&#10;logger = logging.getLogger(__name__)&#10;&#10;class StockNewsAnalysisSystem:&#10;    &quot;&quot;&quot;주식 뉴스 분석 시스템 메인 클래스&quot;&quot;&quot;&#10;&#10;    def __init__(self):&#10;        self.crawler = NaverStockNewsCrawler()&#10;        self.analyzer = NewsAnalyzer()&#10;&#10;    def run_daily_analysis(self, news_limit: int = 10, reports_limit: int = 10) -&gt; dict:&#10;        &quot;&quot;&quot;&#10;        일일 뉴스 분석 실행 (카테고리별 상세 분석 포함)&#10;&#10;        Args:&#10;            news_limit: 크롤링할 뉴스 개수&#10;            reports_limit: 각 카테고리별로 크롤링할 리포트 개수&#10;&#10;        Returns:&#10;            Dict: 전체 분석 결과&#10;        &quot;&quot;&quot;&#10;        logger.info(&quot;--- 일일 주식 뉴스 분석 시작 ---&quot;)&#10;&#10;        try:&#10;            # 1. 뉴스 및 리포트 크롤링&#10;            logger.info(&quot;1단계: 뉴스 및 리포트 크롤링 시작&quot;)&#10;            crawled_data = self.crawler.get_today_summary()&#10;&#10;            if crawled_data['total_count'] == 0:&#10;                logger.warning(&quot;크롤링된 데이터가 없습니다.&quot;)&#10;                return {&quot;error&quot;: &quot;크롤링된 데이터가 없습니다.&quot;}&#10;&#10;            # 크롤링 현황 출력&#10;            logger.info(f&quot;뉴스 크롤링: {len(crawled_data['main_news'])}개&quot;)&#10;            logger.info(f&quot;리포트 크롤링: {len(crawled_data['research_reports'])}개&quot;)&#10;&#10;            # 카테고리별 통계 출력&#10;            category_counts = {}&#10;            for report in crawled_data['research_reports']:&#10;                category = report.get('category_name', 'Unknown')&#10;                category_counts[category] = category_counts.get(category, 0) + 1&#10;&#10;            if category_counts:&#10;                for category, count in category_counts.items():&#10;                    logger.info(f&quot;  {category}: {count}개&quot;)&#10;&#10;            # 2. AI 분석 수행 (카테고리별 상세 분석 포함)&#10;            logger.info(&quot;Gemini API 분석 시작&quot;)&#10;            analysis_result = self.analyzer.analyze_comprehensive_with_categories(crawled_data)&#10;&#10;            # 3. 결과 저장&#10;            self._save_results(crawled_data, analysis_result)&#10;&#10;            logger.info(&quot;분석 완료&quot;)&#10;&#10;            return {&#10;                'crawled_data': crawled_data,&#10;                'analysis_result': analysis_result,&#10;                'status': 'success'&#10;            }&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;분석 시스템 실행 중 오류: {e}&quot;)&#10;            return {&quot;error&quot;: f&quot;시스템 실행 중 오류: {str(e)}&quot;}&#10;&#10;    def _save_results(self, crawled_data: dict, analysis_result: dict):&#10;        &quot;&quot;&quot;분석 결과를 파일로 저장&quot;&quot;&quot;&#10;        timestamp = datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;)&#10;&#10;        # 크롤링 데이터 저장&#10;        with open(f'crawled_data_{timestamp}.json', 'w', encoding='utf-8') as f:&#10;            json.dump(crawled_data, f, ensure_ascii=False, indent=2)&#10;&#10;        # 분석 결과 저장&#10;        with open(f'analysis_result_{timestamp}.json', 'w', encoding='utf-8') as f:&#10;            json.dump(analysis_result, f, ensure_ascii=False, indent=2)&#10;&#10;        logger.info(f&quot;결과 파일 저장 완료: crawled_data_{timestamp}.json, analysis_result_{timestamp}.json&quot;)&#10;&#10;    def print_summary(self, result: dict):&#10;        &quot;&quot;&quot;분��� 결과 요약 출력 (간소화된 버전)&quot;&quot;&quot;&#10;        if 'error' in result:&#10;            print(f&quot;❌ 오류: {result['error']}&quot;)&#10;            return&#10;&#10;        analysis = result['analysis_result']&#10;&#10;        print(&quot;\n&quot; + &quot;-&quot;*50)&#10;        print(&quot;&lt;오늘의 주식 시장 분석 결과&gt;&quot;)&#10;        print(&quot;-&quot;*50)&#10;&#10;        # 뉴스 분석 요약&#10;        if 'news_analysis' in analysis:&#10;            news = analysis['news_analysis']&#10;            print(f&quot;\n 뉴스 분석 ({news.get('news_count', 0)}개)&quot;)&#10;            print(f&quot;   감정: {news.get('overall_sentiment', 'N/A')}&quot;)&#10;            print(f&quot;   점수: {news.get('sentiment_score', 'N/A')}/100&quot;)&#10;            if 'summary' in news:&#10;                print(f&quot;   ���약: {news['summary']}&quot;)&#10;&#10;        # 리포트 분석 요약 (카테고리별)&#10;        if 'reports_analysis' in analysis:&#10;            reports = analysis['reports_analysis']&#10;            print(f&quot;\n 리포트 분석 ({reports.get('reports_count', 0)}개)&quot;)&#10;            print(f&quot;   시장 전망: {reports.get('market_outlook', 'N/A')}&quot;)&#10;&#10;            if 'top_mentioned_stocks' in reports:&#10;                stocks = reports['top_mentioned_stocks'][:5]&#10;                if stocks:&#10;                    print(f&quot;   주목 종목: {', '.join(stocks)}&quot;)&#10;&#10;        # 일일 종합 분석&#10;        if 'daily_report' in analysis:&#10;            daily = analysis['daily_report']&#10;            if 'error' not in daily:&#10;                print(f&quot;\n⭐ 종합 평가&quot;)&#10;                print(f&quot;   시장 감정 점수: {daily.get('market_sentiment_score', 'N/A')}/10&quot;)&#10;                print(f&quot;   신뢰도: {daily.get('confidence_level', 'N/A')}/10&quot;)&#10;&#10;    def print_detailed_category_analysis(self, result: dict):&#10;        &quot;&quot;&quot;카테고리별 상세 분석 결과 출력 (간소화된 버전)&quot;&quot;&quot;&#10;        if 'error' in result or 'category_insights' not in result['analysis_result']:&#10;            return&#10;&#10;        analysis = result['analysis_result']&#10;        insights = analysis['category_insights']&#10;&#10;        if 'category_statistics' in insights:&#10;            print(f&quot;\n&quot; + &quot;-&quot;*50)&#10;            print(&quot;&lt;카테고리별 상세 분석&gt;&quot;)&#10;&#10;            stats = insights['category_statistics']&#10;            for category, data in stats.items():&#10;                print(f&quot;\n {category}&quot;)&#10;                print(f&quot;   리포트 수: {data.get('count', 0)}개&quot;)&#10;                if data.get('mentioned_stocks'):&#10;                    print(f&quot;   언급된 종목: {', '.join(data['mentioned_stocks'][:3])}&quot;)&#10;&#10;def main():&#10;    &quot;&quot;&quot;메인 실행 함수&quot;&quot;&quot;&#10;    print(&quot; 네이버 증권 AI 분석 시스템&quot;)&#10;&#10;    # 시스템 초기화&#10;    system = StockNewsAnalysisSystem()&#10;&#10;    # 분석 실행&#10;    result = system.run_daily_analysis(news_limit=20, reports_limit=5)&#10;&#10;    # 기본 요약 결과 출력&#10;    system.print_summary(result)&#10;&#10;    # 카테고리별 상세 분석 출력 (리포트가 있을 때만)&#10;    system.print_detailed_category_analysis(result)&#10;&#10;    print(f&quot;\n{'-'*50}&quot;)&#10;    print(&quot;&lt;분석 완료&gt;&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>